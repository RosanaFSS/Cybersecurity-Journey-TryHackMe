<h1 align="center">Detecting Adversarial Attacks</h1>
<p align="center"><img width="80px" src="https://github.com/user-attachments/assets/2189e044-0449-4b8d-8b9c-c3dd4f4e52b7"><br>
<p align="center">July 8, 2025<br> Hey there, fellow lifelong learner! I´m <a href="https://www.linkedin.com/in/rosanafssantos/">Rosana</a>, 
and I’m excited to join you on this adventure, part of my <code>428</code>-day-streak in<a href="https://tryhackme.com"> TryHackMe</a>.<br>
<em>Learn how to identify and analyse adversarial attacks</em>.<br>
Access it <a href="https://tryhackme.com/room/idadversarialattacks"</a>here.<br>
<img width="1200px" src="https://github.com/user-attachments/assets/31f77b85-e2ef-4226-b168-a816d4005a77"></p><br>
<h3 align="center">Discover and learn more about AI, ML, and LLM security labs from my TryHackMe journey</h3>

<div align="center"><h6>

|Resource<br><br><br><br>                          |[<code>LLM01</code>](https://genai.owasp.org/llmrisk/llm01-prompt-injection/):2025<br>Prompt<br>Injection<br><br>|[<code>LLM02</code>](https://genai.owasp.org/llmrisk/llm022025-sensitive-information-disclosure/):2025<br>Sensitive<br>Information<br>Disclosure|[<code>LLM03</code>](https://genai.owasp.org/llmrisk/llm032025-supply-chain/):2025<br>Supply<br>Chain<br><br>|[<code>LLM04</code>](https://genai.owasp.org/llmrisk/llm042025-data-and-model-poisoning/):2025<br>Data and<br>Model<br>Poisoning|[<code>LLM05</code>](https://genai.owasp.org/llmrisk/llm052025-improper-output-handling/):2025<br>Improper<br>Output<br>Handling|[<code>LLM06</code>](https://genai.owasp.org/llmrisk/llm062025-excessive-agency/):2025<br>Excessive<br> Agency<br><br>|[<code>LLM07</code>](https://genai.owasp.org/llmrisk/llm072025-system-prompt-leakage/):2025<br>System<br>Prompt<br>Leakage<br>|[<code>LLM08</code>](https://genai.owasp.org/llmrisk/llm082025-vector-and-embedding-weaknesses/):2025<br>Vector and<br>Embedding<br>Weaknesses<br>|[<code>LLM09</code>](https://genai.owasp.org/llmrisk/llm092025-misinformation/):2025<br>Misinformation<br><br><br>|[<code>LLM10</code>](https://genai.owasp.org/llmrisk/llm102025-unbounded-consumption/):2025<br>Unbounded<br>Consumption<br><br>|
|:-------------------------------------------------|:-------:|:-------:|:-------:|:-------:|:-------:|:-------:|:-------:|:-------:|:-------:|:-------:|
|[Input Manipulation<br>& Prompt Injection<br><br>](https://github.com/RosanaFSS/Cybersecurity-Journey-TryHackMe/blob/CTFs-&-Infos/Easy%20%F0%9F%94%97%20-%20Input%20Manipulation%20&%20Prompt%20Injection.md)  |   ✔<br><br><br><br><br>     |         |         |         |         |         |    ✔<br><br><br><br><br>    |         |         |         |
|[LLM Output<br>Handling and<br>Privacy Risks](https://github.com/RosanaFSS/Cybersecurity-Journey-TryHackMe/blob/CTFs-%26-Infos/Easy%20%F0%9F%94%97%20-%20LLM%20Output%20Handling%20and%20Privacy%20Risks.md)       |         |   ✔<br><br><br><br><br>    |         |         |    ✔<br><br><br><br><br>    |         |         |         |         |         |
|[Data Integrity<br>& Model Poisoning<br><br>](https://github.com/RosanaFSS/Cybersecurity-Journey-TryHackMe/blob/CTFs-%26-Infos/Medium%20%F0%9F%94%97%20-%20Data%20Integrity%20%26%20Model%20Poisoning.md)       |         |         | ✔<br><br><br><br><br>        |✔<br><br><br><br><br>         |         |         |         |         |         |         |
|                                                                                                                                                                           |
|Defensive AI<br><br>[AI/ML<br>Security<br>Threats<br>](https://github.com/RosanaFSS/Cybersecurity-Journey-TryHackMe/blob/CTFs-%26-Infos/Easy%20%F0%9F%94%97%20-%20AI-ML%20Security%20Threats.md)<br>[Detecting<br>Adversarial<br>Attacks<br>](https://github.com/RosanaFSS/Cybersecurity-Journey-TryHackMe/blob/CTFs-%26-Infos/Medium%20%F0%9F%94%97%20-%20Detecting%20Adversarial%20Attacks.md)<br>[Defending<br>Adversarial<br>Attacks<br>](https://github.com/RosanaFSS/Cybersecurity-Journey-TryHackMe/blob/CTFs-&-Infos/Medium%20%F0%9F%94%97%20-%20Defending%20Adversarial%20Attacks.md)<br>[AI Forensics<br>](https://github.com/RosanaFSS/Cybersecurity-Journey-TryHackMe/blob/CTFs-&-Infos/Medium%20%F0%9F%94%97%20-%20AI%20Forensics.md)<br>[ContAinment<br>](https://github.com/RosanaFSS/Cybersecurity-Journey-TryHackMe/blob/CTFs-&-Infos/Medium%20%F0%9F%9A%A9%20-%20ContAInment.md)| | | | | | | | | | |

</h6></div>

<h1 align="center">Detecting Adversarial Attacks</h1>


<h2>Task 1 . Introduction</h2>

<br>

<h2>Task 2 . Adversarial Techniques Overview</h2>

<br>

<h2>Task 3 . Understanding FGSM and variants</h2>

<br>

<h2>Task 4 . Identifiying Adversarial Attacks</h2>

![image](https://github.com/user-attachments/assets/b8c3464f-018d-4705-8c18-20e70bb32277)

<br>

<h2>Task 5 . Conclusion</h2>
<p>In this lab, we explored how FGSM, BIM and PGD can generate adversarial examples that trick neural networks. FGSM is quick and simple, but BIM and PGD take it further by applying multiple steps, making the attacks more effective and much harder to detect. PGD, in particular, was the most aggressive, using random starts and repeated refinement to bypass defences that simpler methods could not. This highlights how fragile neural networks can be, often relying on patterns that do not hold up when the input is slightly altered.</p>

<p>To make models more robust, it is important to train them with adversarial examples, apply input preprocessing, and explore architectures that are more resilient by design. Improving defences is not just about boosting accuracy but about thinking realistically about how models will behave under pressure and when deliberately targeted. If you want to explore how to harden and defend models against such attacks, check out the Defending Against Adversarial Attacks room!</p>

<br>
<br>

<h1 align="center">Room Completed</h1>
<p align="center"> <img width="1000px" src="https://github.com/user-attachments/assets/619b7f4c-0c83-4826-a7ec-92f566c94c1a"><br>
<p align="center"> <img width="1000px" src="https://github.com/user-attachments/assets/af6ab2bf-bf1b-4113-8367-f582f22947c7"><br>

<h1 align="center">My TryHackMe Journey</h1>

<div align="center">

| Date              | Streak   | All Time     | All Time     | Monthly     | Monthly    | Points   | Rooms     | Badges    |
| :---------------: | :------: | :----------: | :----------: | :---------: | :--------: | :------  | :-------: | :-------: |
|                   |          |    Global    |    Brazil    |    Global   |   Brazil   |          | Completed |           |
| July 8, 2025      | 428      |     162ⁿᵈ    |      5ᵗʰ     |    368ᵗʰ    |     13ʳᵈ   |  113,589 |    837    |     64   |

</div>

<p align="center"> Global All Time: 162ⁿᵈ <br><img width="300px" src="https://github.com/user-attachments/assets/2da21e9f-428c-44a0-a2ac-82eb742bfbd5" alt="Your Image Badge"><br>
                                              <img width="1000px" src="https://github.com/user-attachments/assets/6b91a2cd-ada7-46d2-9dd8-628ffa878859"><br><br>
                   Brazil All Time:   5ᵗʰ<br><img width="1000px" src="https://github.com/user-attachments/assets/169eb966-8b52-494f-99e3-05e325d3c726"><br><br>
                   Global monthly: 368ᵗʰ<br><img width="1000px" src="hhttps://github.com/user-attachments/assets/1a99efab-354e-4ea7-af42-47c3835e03fe"><br><br>
                   Brazil monthly:   13ʳᵈ<br><img width="1000px" src="https://github.com/user-attachments/assets/e9cbbc3f-a03a-47a4-9c68-aae1a112a490"><br><br></p>
