<h1 align="center">Input Manipulation & Prompt Injection</h1>
<p align="center">2025, November 14  &nbsp; .  &nbsp; Hey! IÂ´m <a href="https://www.linkedin.com/in/rosanafssantos/">Rosana</a>, and Iâ€™m excited to join you on this adventure on my <code>1</code>-day-streak in<a href="https://tryhackme.com"> TryHackMe</a>.<br>Understand the basics of LLM Prompt Injection attacks &nbsp;&nbsp;Access it <a href="https://tryhackme.com/room/inputmanipulationpromptinjection">here</a>.<br><br><img width="1200px" src="https://github.com/user-attachments/assets/b0bb8c4e-a1bb-4489-b8b5-24cda2ff930b"></p><br>
<h3 align="center">Discover and learn more about AI, ML, and LLM security labs from my TryHackMe journey</h3>

<div align="center"><h6>

|Resource<br><br><br><br>                          |[<code>LLM01</code>](https://genai.owasp.org/llmrisk/llm01-prompt-injection/):2025<br>Prompt<br>Injection<br><br>|[<code>LLM02</code>](https://genai.owasp.org/llmrisk/llm022025-sensitive-information-disclosure/):2025<br>Sensitive<br>Information<br>Disclosure|[<code>LLM03</code>](https://genai.owasp.org/llmrisk/llm032025-supply-chain/):2025<br>Supply<br>Chain<br><br>|[<code>LLM04</code>](https://genai.owasp.org/llmrisk/llm042025-data-and-model-poisoning/):2025<br>Data and<br>Model<br>Poisoning|[<code>LLM05</code>](https://genai.owasp.org/llmrisk/llm052025-improper-output-handling/):2025<br>Improper<br>Output<br>Handling|[<code>LLM06</code>](https://genai.owasp.org/llmrisk/llm062025-excessive-agency/):2025<br>Excessive<br> Agency<br><br>|[<code>LLM07</code>](https://genai.owasp.org/llmrisk/llm072025-system-prompt-leakage/):2025<br>System<br>Prompt<br>Leakage<br>|[<code>LLM08</code>](https://genai.owasp.org/llmrisk/llm082025-vector-and-embedding-weaknesses/):2025<br>Vector and<br>Embedding<br>Weaknesses<br>|[<code>LLM09</code>](https://genai.owasp.org/llmrisk/llm092025-misinformation/):2025<br>Misinformation<br><br><br>|[<code>LLM10</code>](https://genai.owasp.org/llmrisk/llm102025-unbounded-consumption/):2025<br>Unbounded<br>Consumption<br><br>|
|:-------------------------------------------------|:-------:|:-------:|:-------:|:-------:|:-------:|:-------:|:-------:|:-------:|:-------:|:-------:|
|[Input Manipulation<br>& Prompt Injection<br><br>](https://github.com/RosanaFSS/Cybersecurity-Journey-TryHackMe/blob/CTFs-&-Infos/Easy%20%F0%9F%94%97%20-%20Input%20Manipulation%20&%20Prompt%20Injection.md)  |   âœ”<br><br><br><br><br>     |         |         |         |         |         |    âœ”<br><br><br><br><br>    |         |         |         |
|[LLM Output<br>Handling and<br>Privacy Risks](https://github.com/RosanaFSS/Cybersecurity-Journey-TryHackMe/blob/CTFs-%26-Infos/Easy%20%F0%9F%94%97%20-%20LLM%20Output%20Handling%20and%20Privacy%20Risks.md)       |         |   âœ”<br><br><br><br><br>    |         |         |    âœ”<br><br><br><br><br>    |         |         |         |         |         |
|[Data Integrity<br>& Model Poisoning<br><br>](https://github.com/RosanaFSS/Cybersecurity-Journey-TryHackMe/blob/CTFs-%26-Infos/Medium%20%F0%9F%94%97%20-%20Data%20Integrity%20%26%20Model%20Poisoning.md)       |         |         | âœ”<br><br><br><br><br>        |âœ”<br><br><br><br><br>         |         |         |         |         |         |         |
|                                                                                                                                                                           |
|Defensive AI<br><br>[AI/ML<br>Security<br>Threats<br>](https://github.com/RosanaFSS/Cybersecurity-Journey-TryHackMe/blob/CTFs-%26-Infos/Easy%20%F0%9F%94%97%20-%20AI-ML%20Security%20Threats.md)<br>[Detecting<br>Adversarial<br>Attacks<br>](https://github.com/RosanaFSS/Cybersecurity-Journey-TryHackMe/blob/CTFs-%26-Infos/Medium%20%F0%9F%94%97%20-%20Detecting%20Adversarial%20Attacks.md)<br>[Defending<br>Adversarial<br>Attacks<br>](https://github.com/RosanaFSS/Cybersecurity-Journey-TryHackMe/blob/CTFs-&-Infos/Medium%20%F0%9F%94%97%20-%20Defending%20Adversarial%20Attacks.md)<br>[AI Forensics<br>](https://github.com/RosanaFSS/Cybersecurity-Journey-TryHackMe/blob/CTFs-&-Infos/Medium%20%F0%9F%94%97%20-%20AI%20Forensics.md)<br>[ContAinment<br>](https://github.com/RosanaFSS/Cybersecurity-Journey-TryHackMe/blob/CTFs-&-Infos/Medium%20%F0%9F%9A%A9%20-%20ContAInment.md)| | | | | | | | | | |

</h6></div>

<h1 align="center">Input Manipulation & Prompt Injection</h1>


<h2>Task 1 . Introduction</h2>

<p><em>Answer the question below</em></p>

<p>1.1. Click me to proceed to the next task.<br>
<code>No answer needed</code></p>

<br>
<h2>Task 2 . System Prompt Leakage</h2>

<p><em>Answer the question below</em></p>

<p>2.1. What do we call the exposure of hidden system instructions?<br>
<code>Leakage</code></p>

<br>
<h2>Task 3 . Jailbreaking</h2>

<p><em>Answer the question below</em></p>

<p>3.1. What evasive technique replaces or alters characters to bypass naive keyword filters?<br>
<code>Obfuscation</code></p>

<br>
<h2>Task 4 . Prompt Injection</h2>

<p><em>Answer the questions below</em></p>

<p>4.1. Which injection type smuggles instructions via uploaded documents, web pages, or plugins?<br>
<code>Indirect</code></p>

<p>4.2. Which injection type places malicious instructions directly in the user input?<br>
<code>Direct</code></p>

<br>
<h2>Task 5 . Challenge</h2>

<p><em>Answer the questions below</em></p>

<p>5.1.What is the prompt injection flag?<br>
<code>THM{pi_33f7a14a468eba7d3bc2d81a4445134c}</code></p>

<img width="1122" height="265" alt="image" src="https://github.com/user-attachments/assets/eebe1984-935a-4c26-9427-aee2539fa665" />


<br>
<br>
<br>
<p>5.2. What is the system prompt flag?<br>
<code>33f7a14a468eba7d3bc2d81a4445134c</code></p>

<img width="1118" height="616" alt="image" src="https://github.com/user-attachments/assets/7bb9531a-a9e5-4bff-872b-73184c4b8e5f" />


<br>
<br>
<br>
<h2>Task 6 . Conclusion</h2>

<p><em>Answer the question below</em></p>

<p>6.1. I can now exploit LLMs using input manipulation!<br>
<code>No answer needed</code></p>

<br>
<br>
<br>

<h2>Completed</h2>

<img width="1902" height="893" alt="image" src="https://github.com/user-attachments/assets/0cf86412-08ef-45e9-8e04-ff61190c597c" />

<br>
<br>
<br>

<img width="1909" height="901" alt="image" src="https://github.com/user-attachments/assets/6de06662-d076-45c6-9472-3ff1628c73f9" />

<br>
<br>
<br>

<h1 align="center">My TryHackMe Journey ãƒ» 2025, November</h1>

<div align="center"><h6>

| Date   | Room                                  |Streak   |All Time<br>Global|All Time<br>Brazil|Monthly<br>Global|Monthly<br>Brazil|Points|Rooms<br>Completed|Badges|
|:------:|:--------------------------------------|--------:|------------:|------------:|------------:|------------:|------------:|------------:|------------:|
|14      |Easy ðŸ”— - Input Manipulation & Prompt Injection |   1    |      95áµ—Ê°    |      4áµ—Ê°     |  1,290áµ—Ê°   |     12nd     |    132,822  |    1,020    |    80     |

</h6></div><br>

<br>

<p align="center">Global All Time:   95áµ—Ê°<br><img width="250px" src="https://github.com/user-attachments/assets/27df005e-cd59-425e-a60d-4614c8e9adbc"><br>
                                              <img width="1200px" src="https://github.com/user-attachments/assets/7abb8881-aeb9-4f23-82c4-3a868d4f846b"><br><br>
                  Brazil All Time:     4áµ—Ê°<br><img width="1200px" src="https://github.com/user-attachments/assets/96f29793-b6e8-496b-a804-3adde7a18ebd"><br>
                  Global monthly:    1,290áµ—Ê°<br><img width="1200px" src="https://github.com/user-attachments/assets/68c9eb3c-28a0-4694-87d2-d46b2e4f02ae"><br>
                  Brazil monthly:      12nd<br><img width="1200px" src="https://github.com/user-attachments/assets/5cd0c5d0-0c01-42a3-89c7-3eab1ccd816b"></p>


<h1 align="center">Thanks for coming!</h1>
<p align="center">Follow me on <a href="https://medium.com/@RosanaFS">Medium</a>, here on <a href="https://github.com/RosanaFSS/TryHackMe">GitHub</a>, and on <a href="https://www.linkedin.com/in/rosanafssantos/">LinkedIN</a>.</p>






<br>
